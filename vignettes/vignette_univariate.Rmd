---
title:  |   
  | HMSC-R 3.0: Getting started with HMSC-R: univariate models
author: "Gleb Tikhonov, Oystein H. Opedal, Nerea Abrego, Aleksi Lehikoinen & Otso Ovaskainen"
date: "11 March 2019"
output:
  pdf_document: default
  html_document: default
---

# Introduction
The Hierarchical Modelling of Species Communities (HMSC) framework is a statistical framework for analysis of multivariate data, typically from species communities. Here, we demonstrate how to get started with HMSC. While HMSC is primarily meant for multivariate data, this vignette illustrates the basics with univariate models.

To get HMSC in use, you need to first install it [link](https://github.com/hmsc-r/HMSC) and the load it

```{r message = F}
library(Hmsc)
```

We then set the random number seed to make the resulted here reproducable by the user

```{r message = F}
set.seed(1)
```

# Linear model
As the first case study, we will apply HMSC to fit a univariate linear model. To relate the results to something that we expect the reader to be familiar to, we will also apply the basic `lm` function to the same data and compare the results.

## Generating simulated data
For illustrative purposes, we use here simulate data for which we know the parameter values.

```{r}
n = 50
x = rnorm(n)
alpha = 0
beta = 1
sigma = 1
L = alpha + beta*x
y = L + rnorm(n, sd = sigma)
plot(x,y)
```

Here `n` is the number of datapoints, `x` is a continuous covariate, alpha and beta are the true parameters for intercept and slope, `L` is the linear predictor, and `y` is the response variable. We note that as the data are simulated by the standard linear model, they will conform the assumptions of the linear model.

## Fitting models and looking at parameter estimates
The standard way to analyze these data with a linear model (with the maximum likelihood inference) is to use the `lm` function:

```{r}
da = data.frame(x,y)
m.lm = lm(y ~ x, data=da)
summary(m.lm)
```

We note that, as expected, the parameter estimates roughly correspond to the values we assumed for the intercept ($\alpha=0$) and slope ($\beta=1$) when generating the data.

To fit the analogous model with HMSC, we first construct the model as

```{r}
Y=as.matrix(y)
XData = data.frame(x=x)
m.hmsc = Hmsc(Y=Y, XData=XData, XFormula=~x)
```

While the `lm` function constructs the model and fits it at the same time, the `Hmsc` function only constructs the model object. To fit the model (with Bayesian inference), we write

```{r}
m.hmsc = sampleMcmc(m.hmsc, thin = 2, samples = 1000, transient = 500,
                    nChains = 2, verbose = 500)
```

Here we have selected some parameters (`thin`, `samples`, `transient`, `nChains`) that control how the parameters are estimated (more precisely, how the posterior distribution is sampled). We will ignore these for a moment but return to their meaning soon. The main thing is that now the model object `m.hmsc` also included estimated parameters, in the same way as the object `m.lm` includes the parameters estimated by the `lm` function.

To see the parameter estimates, we may e.g. extract the posterior distribution from the model object and convert it as a coda object. 

```{r}
mpost = convertToCodaObject(m.hmsc)
summary(mpost$Beta)
```

To assess model fit in terms of $R^2$, we can first computed the posterior predictive distribution, and then evaluate the model fit with the help of that.

```{r}
preds.hmsc.posterior = computePredictedValues(m.hmsc)
evaluateModelFit(hM=m.hmsc, predY=preds.hmsc.posterior)
```

Note that the parameter estimates and $R^2$ given by HMSC are consisted with those given by the lm function. We however note that the two approaches are not identical as lm applies the maximum likelihood framework (and thus e.g. yields confidence intervals) whereas HMSC applies the Bayesian framework (and thus e.g. assumes prior distributions and yields credible intervals). The other measure of model fit 'RMSE' refer to root-mean-square error.

## Checking MCMC diagnostics

Let us then turn to the meaning of the parameters that guide posterior sampling in the MCMC algorithm. We first plot the trace-plots of the beta-parameters.

```{r}
plot(mpost$Beta)
```

The black and red colors show the two (`nChains=2`) independent MCMC chains. Both chains start from iteration 501, as by `transient=500` we have chosen ignore iterations before that as a possible transient. The chains have run in total 2500 iterations, as we selected to obtain 1000 samples, and we have recorded only every second step (`thin=2`) of the iterations.

These trace-plots look essentially as good as they can ever look like. First of all, the two chains (the black and red results) yield essentially identical results. Second, the chains mix very well, i.e. they go fast up and down without any apparent autocorrelated. Third, it looks like the chains have reached a stationary distribution, as e.g. the first half of the recorded iterations looks identical to the second half of the recorded iterations.

We may look at the mixing also in terms of effective sample size and potential scale reduction factor.

```{r}
effectiveSize(mpost$Beta)
gelman.diag(mpost$Beta,multivariate=FALSE)$psrf
```

We observe that the effective sample sizes are very close to the theoretical value of the actual number of samples, which is 2000 (1000 per chain). This indicates that there is very little autocorrelation among consecutive samples. The potential scale reduction factors are very close to one, which indicates that two chains gave consistent results, as suggested by visual inspection of the plots.

In summary, the MCMC diagnostics did not indicate any problems with MCMC convergence. This means that the posterior sample is likely to represent well the true posterior distributions, and thus the inference from the model can be trusted. If the MCMC convergence would have indicated problems, we should have refitted the model using different parameters. If the trace-plots would have suggested a present of a transient (the early iterations would have looked different from the later iterations), we should have increased the amount of transient (also called burn-in) iterations to be discarded. If the chains would have shown autocorrelations and/or differed from each other, we should have increased the number of iterations. This can be done by increasing either the number of samples, or by keeping the number of samples fixed but increasing thinning. We recommend the latter, as increasing the number of samples can make the model objects very big and result in slow postprocessing. Thus, if one needs to run a million iterations, we recommend doing so by `samples=1000` and `thin=1000` rather than `samples=1000000` and `thin=1`. In our view, 1000 samples are typically sufficient to evaluate e.g. posterior means and credible intervals with sufficient accuracy.

## Checking the assumptions of the linear model

We finally note that when applying the linear model, it is a good practice to examine if the assumptions of the linear model are valid. This can be done e.g. by constructing the following diagnostic plots.

```{r}
nres.lm = rstandard(m.lm)
preds.lm = fitted.values(m.lm)
par(mfrow=c(1,2))
hist(nres.lm)
plot(preds.lm,nres.lm)
abline(a=0,b=0)
```

The first plot shows that the residuals conform well to the normal distribution, and the second plot shows that the residuals are homoscedastic. This is not surprising, as the data were simulated from the linear model.

Structral model assumptions can be checked also with HMSC basically in the same way as with the standard linear model. However, while with the linear model simply typing plot(m.lm) would provide many diagnostic plots "automatically", with HMSC there is no such built-in functionality. This is because typical applications of HMSC relate to much more complex models where it is not straightforward to decide what a "standard" diagnostic plot should be. To generate diagnostic plots with HMSC, we first summarize the posterior predictive distribution into posterior mean and then extract and standardize the residuals.

```{r}
preds.hmsc = apply(preds.hmsc.posterior, FUN=mean, MARGIN=1)
nres.hmsc = scale(y-preds.hmsc)
par(mfrow=c(1,2))
hist(nres.hmsc)
plot(preds.hmsc,nres.hmsc)
abline(a=0,b=0)
```

These diagnostic plots are essentially identical to those obtained for the linear model. This is to be expected, as we observed earlier that the parameter estimates (and hence the fitted values and residuals) were consistent between the two approaches.

# Generalized linear models
While many kinds of generalized linear models is quite straightforward in the univariate framework, the multivariate and hierarchical nature of HMSC makes it quite challenging to implement link functions and error distributions. For this reason, HMSC-R 3.0 allows only four types of response variables. The first one is the assumption of linear model with normally distributed residuals. As this has been set as the default option, we defined our model above simply as

```{r}
m.hmsc = Hmsc(Y=Y, XData=XData, XFormula=~x)
```

whereas the full version that makes the assumption of normality transparent would be

```{r}
m.hmsc = Hmsc(Y=Y, XData=XData, XFormula=~x, distr = "normal")
```

## Probit model for presence-absence data

A very typical case with community data is that of presence-absence data, in which case the response variable is either 0 (species absent) or 1 (species present). In HMSC-R, such data are modelled with probit regression. For those readers not familiar with probit regression, we note that probit-regression is similar to logistic regression, it just applies a slightly different link-function. We next repeat the above exercise but do so for data that conform the assumptions of probit regression.
 
```{r}
y = 1*(L+ rnorm(n, sd = 1)>0)
plot(x,y)
Y=as.matrix(y)
m.hmsc = Hmsc(Y=Y, XData=XData, XFormula=~x, distr="probit")
m.hmsc = sampleMcmc(m.hmsc, thin = 2, samples = 1000, transient = 500,
                    nChains = 2, verbose = 500)
mpost = convertToCodaObject(m.hmsc)
summary(mpost$Beta)
effectiveSize(mpost$Beta)
gelman.diag(mpost$Beta,multivariate=FALSE)$psrf
preds.hmsc.posterior = computePredictedValues(m.hmsc)
evaluateModelFit(hM=m.hmsc, predY=preds.hmsc.posterior)
```

Compared to the case of the linear model, we observe that the effective sample size is somewhat (achieving MCMC convergence is generally more challenging in non-normal models), and the parameter estimates include more uncertainty (0/1 data are less informative than normally distributed data). We further note that instead of the $R^2$ of the linear model, model fit is now evaluated in terms of `AUC` and Tjur $R^2$.

## Poisson model for count data

Another typical case with community data is that of count data, in which case the response variable is a non-negative integer 0,1,2,3,..., representing e.g. the count of indivuals. In HMSC-R, such data can be modelled with poisson regression. We next repeat the above exercise but do so for data that conform the assumptions of Poisson regression.
 
```{r}
y = y = rpois(n, lambda = exp(L))
plot(x,y)
Y=as.matrix(y)
m.hmsc = Hmsc(Y=Y, XData=XData, XFormula=~x, distr="poisson")
m.hmsc = sampleMcmc(m.hmsc, thin = 2, samples = 1000, transient = 500,
                    nChains = 2, verbose = 500)
mpost = convertToCodaObject(m.hmsc)
summary(mpost$Beta)
effectiveSize(mpost$Beta)
gelman.diag(mpost$Beta,multivariate=FALSE)$psrf
preds.hmsc.posterior = computePredictedValues(m.hmsc, expected = FALSE)
evaluateModelFit(hM=m.hmsc, predY=preds.hmsc.posterior)
```

In this case, the MCMC diagnostics are much worse than for the probit model. Unfortunately, achieving mixing for Poisson model in the HMSC context is highly challenging. To get results that can be trusted, one should increase the thinning and run the model longer.

For the Poisson model, many kinds of measures of model fit are given. The measure `SR2` can be viewed as a pseudo-$R^2$. Whereas the $R^2$ of a linear model can be computed as the squared pearson correlation between predicted and true values, we have computed `SR2` as the squared spearman correlation between observed and predicted values. As the Poisson model predicts counts, it can be used to separate whether a species is present (count>0) or absent (count=0). For evaluating how well species occurrences (indicated by `O.`) are predicted, same measures (`AUC` and Tjur $R^2$) are used as for the probit model. Sometimes it mac also be of interest to examine how well the model is able to predict abundance variation in cases where the species is present, and thus ignoring absences. This is done with the measures indicated by `C.`, where C refers to "conditional on presence". Note that in this case we have generated the predictions with the option `expected = FALSE`. In this case, the predictions are not expected values (e.g. on average we expect to see 2.3 individuals), but a posterior predictive distribution of data (i.e., actual counts 0,1,2,3,... that involve the Poisson error). We have selected `expected = FALSE` so that presence-absences can be inferred from the predictions.

## Log-normal Poisson model for count data

The Poisson model is often not a good model for ecological count data as it does not allow sufficient amount of variation around the expectation. To allow for more variation, HMSC-R includes the possibility to fit a log-normal Poisson model. We note that another standard option would be to fit the Negative Binomial model, but this model is not included currently in HMSC-R. We next repeat the above exercise but do so for data that conform the assumptions of log-normal Poisson regression.
 
 
```{r}
y = rpois(n, lambda = exp(L+rnorm(n, sd=2)))
plot(x,y)
Y=as.matrix(y)
m.hmsc = Hmsc(Y=Y, XData=XData, XFormula=~x, distr="lognormal poisson")
m.hmsc = sampleMcmc(m.hmsc, thin = 2, samples = 1000, transient = 500,
                    nChains = 2, verbose = 500)
mpost = convertToCodaObject(m.hmsc)
summary(mpost$Beta)
effectiveSize(mpost$Beta)
gelman.diag(mpost$Beta,multivariate=FALSE)$psrf
preds.hmsc.posterior = computePredictedValues(m.hmsc, expected = FALSE)
evaluateModelFit(hM=m.hmsc, predY=preds.hmsc.posterior)
```

We note that the output is similar to that given for the standard Poisson model.

## Hurdle models

Ecological data are often dominated by zeros, i.e. they are zero-inflated. HMSC does not include the much used zero-inflated Poisson model as that would be challenging to implement in the multivariate and hierarchical context. However, it is always possible to apply the closely-related Hurdle model, by analyzing separately occurrence data `1*(Y>0)`by probit regression, and abundance conditional on presence `Y[Y==0] = NA` by a suitable model of abundance. We note that these two aspects of the data (occurrence and abundance conditional on presence) are statistically independent of each other, and thus it is interesting to compare results obtained for them.  

## How to select the best model?

When fitting generalized linear models with the maximum likelihood framework, a common way of comparing models is to use AIC. For example, in case of count data, AIC could be used to compare the Poisson model, the Negative Binomial model, and the Zero-Inflated Poisson model. In case of HMSC-R, model selection is recommended to be conducted through evaluating predictive performance through cross-validation approaches. We refer to the more advanced vignettes for how to do so in practice.

# Mixed models

xxx

