---
title:  |
  | HMSC-R 3.0: Getting started with HMSC-R: high-dimensional multivariate models
author: "Gleb Tikhonov, Oystein H. Opedal, Nerea Abrego, Aleksi Lehikoinen & Otso Ovaskainen"
date: "11 March 2019"
output:
   
  pdf_document: default
  word_document: default
  html_document: default
---

# Introduction
The Hierarchical Modelling of Species Communities (HMSC) framework is a statistical framework for analysis of multivariate data, typically from species communities. We assume that the reader has already gone through the vignettes "HMSC-R 3.0: Getting started with HMSC-R: univariate models" and "HMSC-R 3.0: Getting started with HMSC-R: low-dimensional multivariate models". Here we continue with high-dimensional multivariate models, i.e. models for species rich communities consisting of many species.

The main difference between the low- and high-dimensional cases is that only the latter one truly benefits from the hierarchical structure of HMSC. By the hierarchical structure we refer to the species responses to enviromental covariates ($\beta$) being modelled as a function of species traits and phylogenetic relationships. In this context, one species can be considered as one data point. Thus, if there are only a handfull of species, there are no sufficient data to model the influence of traits and phylogenies. In contrast, if there are many (say, several tens) of species, accounting for traits and phylogenies becomes meaningfull.

To get HMSC in use, you need to first install it [https://github.com/hmsc-r/HMSC] and then load it.

```{r message = F}
library(Hmsc)
library(corrplot)
set.seed(8)
```

We also loaded the library corrplot as we will make plots with that, and we set the random number seed to make the results presented here reproducible. This time we did not choose `set.seed(1)` but instead `set.seed(8)` as that results in a simulated phylogeny that fits better our purpose.

# Generating simulated data for a large species community

## Simulating phylogeny and species traits
As an example, we will consider a community consisting of 100 species. To bring an evolutionary perspective to our data and analyses, we start by simulating a phylogeny showing how these species have evolved from their common ancestor. This can be done using the `rcoal` function of the `ape` package.

```{r}
ns = 100
phy = rcoal(n=ns, tip.label = NULL, br = "coalescent")
plot(phy)
```

We will next generate four simulated traits for each of the 100 species. For the sake of illustration will call these traits as *habitat use* (trait 1, to be abbreviated as H),*thermal optimum* (trait 2,  to be abbreviated as T), *fecundity* (trait 3,  to be abbreviate as F) and *body size* (trait 4,  to be abbreviate as B).

We assume that traits 1-3 are phylogenetically constrained so that they have evolved according to the diffusion model of trait evoluation. We further assume that traits 2 and 3 are positively correlated with each other so that species with high thermal optimum tend to have high fecundity. These assumptions can be implemented by randomizing the traits from a multivariate normal distribution where the variance-covariance matrix is a Kronecker product between the phylogenetic correlation matrix `C` and a trait-to-trait variance-covariance matrix `V`. The phylogenetic correlation matrix `C` can be generated from the phylogenetic tree using the function `vcv`of the `ape` package.

```{r}
C = vcv(phy, model = "Brownian", corr = TRUE)
V = diag(3)
V[[1]] = 1
V[[2,3]] = V[[3,2]] = 0.9
set.seed(1)
traits = matrix(mvrnorm(n = 1, mu = rep(0,3*ns), Sigma=kronecker(V,C)), ncol = 3)
traits = scale(traits)
for (i in 1:3){
   ma = max(traits[,i])
   mi = min(traits[,i])
   traits[,i] = 2*(traits[,i]-mi)/(ma-mi)-1
}
```

Above, we have re-set the random number seed to generate trait values that fit to our purpose. After randomizing the values of the traits from a multivariate normal distribution, we have scaled them so that -1 is the smallest and +1 is the largest value for each trait.

We assume that body size is independent of the phylogeny. This may be the case for example if there is strong selection on body size, if the species-specific trait optimuma for body size are unrelated to the locations of the species in the phylogeny, and if the genetic architecture underlying body size allows for its rapid evolution in the species group we are considering. Thus, we simply randomize body sizes independently from the phylogeny or the the other traits. To include in our analyses both continuous and categorical traits, we assume that body size is classified to three classes: small (-1), intermediate (0) and large (+1).

```{r}
traits=cbind(traits,rnorm(n=ns))
tmp = traits[,4]
traits[,4] = 0
traits[tmp>0.6,4] = 1
traits[tmp<(-0.6),4] = -1
colnames(traits) = c("habitat.use","thermal.optimum","fecundity","body.size")
traits = as.data.frame(traits)
```

We next visualize the trait distributions by plotting them next to the phylogenetic tree.

```{r}
par(fig = c(0,0.6,0,0.8), mar=c(6,0,2,0))
plot(phy, show.tip.label = FALSE)
par(fig = c(0.6,0.9,0.025,0.775), mar=c(6,0,2,0), new=T)
plot.new()
image.plot(t(traits),axes=FALSE,legend.width = 3,legend.shrink=1,
           col = colorRampPalette(c("blue","white","red"))(200))
text(x=0.83,y=0.72,srt = 90,  "S", cex=0.9, pos = 4)
text(x=0.93,y=0.72,srt = 90,  "T", cex=0.9, pos = 4)
text(x=1.03,y=0.72,srt = 90,  "F", cex=0.9, pos = 4)
text(x=1.13,y=0.72,srt = 90,  "B", cex=0.9, pos = 4)
```

As expected, the traits 1-3 (H, T and F) show a clear phylogenetic signal, i.e. related species show similar trait values. Additionally, traits T and F are positively correlated to each other. Traits H may appear to be correlated with the traits T and F, as e.g. the lower part of the graph includes a large number of species that have simultaneously a high value for H and a low value for T and F. However, this apparent correlation is generated simply because also the trait H is phylogenetically constrained. Beyond that, by our assumptions it is independent of the traits T and F. In line with our assumptions, the figure suggests that variation in trait 4 (B) is independent of the phylogeny and of the other traits.

## Simulating envrionmental and species data
As the next step, we simulate the environmental and species data. With respect to environmental variation, we assume that there is variation in habitat type and climatic conditions. Concerning the habitat types, we assume that the sampling units are located either in open habitats or in forest habitats. Concerning climatic variation, we assume that the sampling units differ in their thermal conditions, which we characterize by a continuous covariate.

```{r}
set.seed(1)
n = 50
habitat = factor(sample(x=c("forest","open"),size=n,replace=TRUE))
climate = rnorm(n)
```

The next step is to define the species niches, i.e. how the species abundances depend on the match between their traits and the environmental conditions.

```{r}
L = matrix(0,nrow=n,ncol=ns)
for (i in 1:n){
   L[i,] = L[i,] + traits$fecundity
   L[i,] = L[i,] + (if(habitat[i]=="forest"){1}else{-1})*traits$habitat.use
   L[i,] = L[i,] - (climate[i]-traits$thermal.optimum)^2
}
```

In the script above, we assumed that the fecundity of the species has an additive effect of the linear predictor, so that species with higher fecundity are more abundant. We further assumed that the trait habitat use measures the preference of teh species to forests, so that for forest habitats we add this trait value to the linear predictor whereas for open habitats we substract it from the linear predictor. We have further subtracted the squared difference between the climatc conditions at the sampling unit and the species thermal optimum, making the linear predictor smaller if these two do not match. 

Finally, we assume that body size influences the competition among the species, so that large bodied species compete for certain types of resources, whereas small bodied species compete for other types of resources, and species with intermediate body size compete for a third kind of resources. We implement this by assuming that a subset of species pairs belonging to the same body size class show a negative correlation with each other.

```{r}
set.seed(1)
rho = -0.25
W = diag(ns)
for(repl in 1:1000){
   spp = sample(1:ns,2)
   W1 = W
   W1[spp[1],spp[2]] = rho
   W1[spp[2],spp[1]] = rho
   if(min(eigen(W1)$values)>0){W=W1}
}
min(eigen(W)$values)
print(paste0("number of competing species pairs: ",sum(W==rho)/2))
```

The reason why we did not assume that all species pairs belonging to the same body size class would show a strong negative correlation with each other is logically impossible. Thinking in terms of species occurrence, assume that we would like to implement a strong avoidance among species A, B and C. We could start by assuming that species A and B do not occupy the same sampling units, so that a sampling unit is occupied either by species A or by species B. We could then continue by likewise assuming that species B and C avoid each other and thus that a sampling unit is occupied either by species B or by species C. But these two assumptions lead to the situation where the species A and C are found from the same sampling units, because they both avoid species B. Thus, it is not possible to assume further that due to strong competition between species A and C, these two would also occupy different sampling units. In the above script, we check whether the smalles eigenvalue of the correlation matrix `W` is positive, i.e. if the matrix `W` is positive definite. The condition of positive definiteness corresponds to the intuitive assumption that the associations must be logically feasible, in the sense discussed above. In the above script, the more negative the correlation `rho` between a competing species pair is assumed, the smaller will be the number of species pairs that can show that negative correlation with each other. We note that the situation is not the identical with respect to positive associations. For example, it can be that all species occur in some of the sampling units whereas none of them occur in some other sampling units, creating a strong positive association among all species pairs.

We next implement the outcome of competitive effects by randomizing from multivariate normal distribution where the variance-covariance matrix is set to the above constructed correlation matrix, and adding these random variates to the linear predictor.

```{r}
a = mvrnorm(n=n, mu=rep(0,ns), Sigma=W)
L = L + a
```

To generate the species data, we need to decide about the link function and error distribution. For simplicity, we assume here that the data are normally distributed, and thus we simply add some independent residual variation, where we assume the variance parameter to be identical for each species. Finally, we add to the data matrix the species names, as given by the tip-labels of the phylogeny.

```{r}
Y = L = mvrnorm(n=n, mu=rep(0,ns), Sigma=diag(ns))
colnames(Y) = phy$tip.label
```

#HMSC analyses of the data with the "correct" model.

We are next ready to analyze the data with HMSC. First, we create a data frame of the environmental covariates.

```{r}
XData = data.frame(climate=climate, habitat=habitat)
```


To analyze these data with HMSC, we construct the model as

```{r}
studyDesign = data.frame(sample = sprintf('sample_%.3d',1:n))
rL = HmscRandomLevel(units = studyDesign$sample)
XFormula = ~habitat + poly(climate,degree = 2,raw = TRUE)
TrFormula = ~habitat.use + thermal.optimum + fecundity
m = Hmsc(Y=Y, XData=XData, XFormula = XFormula,
         TrData = traits, TrFormula = TrFormula,
         phyloTree = phy,
         studyDesign=studyDesign, ranLevels=list(sample=rL))
```

Thus, with the XFormula, we have specified that we assume additive effects of the two covariates $x_1$ and $x_2$, i.e. we assume the same model that we used to generate the data. We next choose the MCMC sampling parameters and fit the model.

```{r}
nChains = 2
thin = 1
samples = 10
transient = 5
verbose = 0
m = sampleMcmc(m, thin = thin, samples = samples, transient = transient,
                    nChains = nChains, verbose = verbose)
```
##MCMC convergence

```{r}
mpost = convertToCodaObject(m)
par(mfrow=c(2,1))
hist(effectiveSize(mpost$Beta), main="ess(beta)")
hist(gelman.diag(mpost$Beta,multivariate=FALSE)$psrf, main="psrf(beta)")
#hist(effectiveSize(mpost$Omega[[1]]), main="ess(omega)")
#hist(gelman.diag(mpost$Omega[[1]],multivariate=FALSE)$psrf, main="psrf(omega)")

```

The convergence diagnostics xxx

## Model fit and variance partitioning

```{r}
preds = computePredictedValues(m)
MF = evaluateModelFit(hM=m, predY=preds)
hist(MF$R2,xlim = c(0,1))
```

XXX

```{r}
head(m$X)
```

XXX

```{r}
VP = computeVariancePartitioning(m, group = c(1,1,2,2),groupnames=c("habitat","climate"))
plotVariancePartitioning(m, VP = VP)
```

XXX

## Parameter estimates
Let us first visualize the $\beta$ parameters.

```{r}
postBeta = getPostEstimate(m, parName="Beta")
plotBeta(m, post=postBeta, param="Support", plotTree = TRUE, supportLevel = 0.95,spNamesNumbers = c(F,F))
```

Let us then visualize the $\gamma$ parameters.

```{r}
postGamma = getPostEstimate(m, parName="Gamma")
plotGamma(m, post=postGamma, param="Support", supportLevel = 0.95)
```

Associations

```{r}
OmegaCor = computeAssociations(m)
supportLevel = 0.95
toPlot = ((OmegaCor[[1]]$support>supportLevel) 
          + (OmegaCor[[1]]$support<(1-supportLevel))>0)*OmegaCor[[1]]$mean
corrplot(toPlot, method = "color", 
         col=colorRampPalette(c("blue","white","red"))(200),
         title=paste("random effect level:",m$rLNames[1]), mar=c(0,0,1,0))
```

```{r}
supportLevel = 0.95
neg = OmegaCor[[1]]$support<(1-supportLevel)
W[neg]
sum(neg)
```


Phylogenetic signal

```{r}
summary(mpost$Rho)
```

XXX

## Gradient plots

XXX



```{r}
Gradient = constructGradient(m,focalVariable = "climate")
predY = predict(m, XData=Gradient$XDataNew, studyDesign=Gradient$studyDesignNew, ranLevels=Gradient$rLNew, expected=TRUE)
plotGradient(m, Gradient, pred=predY, measure="T", index=3, showData = TRUE, jigger = 0.2)
```

XX

```{r}
Gradient = constructGradient(m,focalVariable = "habitat")
predY = predict(m, XData=Gradient$XDataNew, studyDesign=Gradient$studyDesignNew, ranLevels=Gradient$rLNew, expected=TRUE)
plotGradient(m, Gradient, pred=predY, measure="T", index=2, showData = TRUE, jigger = 0.2)
```

