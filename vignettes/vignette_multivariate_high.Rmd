---
title:  |
  | HMSC-R 3.0: Getting started with HMSC-R: high-dimensional multivariate models
author: "Gleb Tikhonov, Oystein H. Opedal, Nerea Abrego, Aleksi Lehikoinen & Otso Ovaskainen"
date: "11 March 2019"
output:
   
  pdf_document: default
  word_document: default
  html_document: default
---

# Introduction
The Hierarchical Modelling of Species Communities (HMSC) framework is a statistical framework for analysis of multivariate data, typically from species communities. We assume that the reader has already gone through the vignettes "HMSC-R 3.0: Getting started with HMSC-R: univariate models" and "HMSC-R 3.0: Getting started with HMSC-R: low-dimensional multivariate models". Here we continue with high-dimensional multivariate models, i.e. models for species rich communities consisting of many species.

The main difference between the low- and high-dimensional cases is that only the latter one truly benefits from the hierarchical structure of HMSC. By the hierarchical structure we refer to the species responses to environmental covariates being modelled as a function of species traits and phylogenetic relationships. In this context, each species can be considered as one data point. Thus, if there are only a handful of species, there are no sufficient data to model the influence of traits and phylogenies. In contrast, if there are many (say, several tens) of species, accounting for traits and phylogenies becomes meaningful.

To get HMSC in use, you need to first install it [https://github.com/hmsc-r/HMSC] and then load it.

```{r message = F}
library(Hmsc)
library(corrplot)
set.seed(8)
```

We also loaded the library corrplot as we will make plots with that, and we set the random number seed to make the results presented here reproducible. This time we did not choose `set.seed(1)` but instead `set.seed(8)` as that results in a simulated phylogeny that fits better our purpose.

# Generating simulated data for a large species community

## Simulating phylogeny and species traits
As an example, we will consider a community consisting of 50 species. To bring an evolutionary perspective to our analyses, we start by simulating a phylogeny describing how the species have evolved from their common ancestor. We simulate a phylogeny with the `rcoal` function of the `ape` package.

```{r}
ns = 50
phy = rcoal(n=ns, tip.label = sprintf('species_%.3d',1:ns), br = "coalescent")
plot(phy, show.tip.label = FALSE, no.margin = TRUE)
```

We will next generate four simulated traits for each of the `r ns` species. For the sake of illustration we call these traits as habitat preference for forest (trait 1, to be abbreviated as H), thermal optimum (trait 2, to be abbreviated as T), fecundity (trait 3, to be abbreviated as F) and body size (trait 4, to be abbreviated as B). 

We assume that the traits 1-3 are phylogenetically constrained so that they have evolved according to the diffusion model of trait evolution. We further assume that traits 2 and 3 are positively correlated with each other so that species with high thermal optimum tend to have high fecundity. These assumptions can be implemented by randomizing the traits from a multivariate normal distribution where the variance-covariance matrix is a Kronecker product between the phylogenetic correlation matrix `C` and a trait-to-trait variance-covariance matrix `V`. The phylogenetic correlation matrix `C` can be generated from the phylogenetic tree using the function `vcv`of the `ape` package.

```{r}
C = vcv(phy, model = "Brownian", corr = TRUE)
spnames = colnames(C)
V = diag(3)
V[[1]] = 1
V[[2,3]] = V[[3,2]] = 0.9
set.seed(1)
rho = 0.7
traits = matrix(mvrnorm(n = 1, mu = rep(0,3*ns),
                        Sigma=kronecker(V,rho*C+(1-rho)*diag(ns))), ncol = 3)
traits = scale(traits)
for (i in 1:3){
   ma = max(traits[,i])
   mi = min(traits[,i])
   traits[,i] = 2*(traits[,i]-mi)/(ma-mi)-1
}
rownames(traits) = spnames
```

Here the parameter `rho` sets the extent to which the traits are phylogenetically constrained. With `rho` equalling one, the traits would distributed exactly following the diffusion model of trait evolution, whereas the part  `1-rho` is species-specific independent residual variation.

Above, we have re-set the random number seed to generate trait values that fit to our purpose. After randomizing the values of the traits from a multivariate normal distribution, we have scaled them so that -1 is the smallest and +1 is the largest value for each trait.

We assume that body size is independent of the phylogeny. This may be the case for example if there is strong selection on body size, if the species-specific trait optima for body size are unrelated to the locations of the species in the phylogeny, and if the genetic architecture underlying body size allows for its rapid evolution. We simply randomize body sizes independently from the phylogeny or theother traits. For illustrative purposes, we wish to include in our analyses both continuous and categorical traits. To do so, we assume that body size is classified to three classes: small (-1), intermediate (0) or large (+1).

```{r}
traits=cbind(traits,rnorm(n=ns))
tmp = traits[,4]
traits[,4] = 0
traits[tmp>0.6,4] = 1
traits[tmp<(-0.6),4] = -1
colnames(traits) = c("habitat.use","thermal.optimum","fecundity","body.size")
traits = as.data.frame(traits)
```

We next visualize the trait distributions by plotting them next to the phylogenetic tree.

```{r}
par(fig = c(0,0.6,0,0.8), mar=c(6,0,2,0))
plot(phy, show.tip.label = FALSE)
par(fig = c(0.6,0.9,0.025,0.775), mar=c(6,0,2,0), new=T)
plot.new()
image.plot(t(traits),axes=FALSE,legend.width = 3,legend.shrink=1,
           col = colorRampPalette(c("blue","white","red"))(200))
text(x=0.83,y=0.72,srt = 90,  "H", cex=0.9, pos = 4)
text(x=0.93,y=0.72,srt = 90,  "T", cex=0.9, pos = 4)
text(x=1.03,y=0.72,srt = 90,  "F", cex=0.9, pos = 4)
text(x=1.13,y=0.72,srt = 90,  "B", cex=0.9, pos = 4)
```

As expected, the traits 1-3 (H, T and F) show a clear phylogenetic signal, i.e. related species show similar trait values. Additionally, traits T and F are positively correlated to each other. Trait H may appear to be associated with the traits T and F, as e.g. the lower part of the graph includes a large number of species that have simultaneously a high value for H and a low value for T and F. However, we assumed that trait H varies independently of the traits T and F, and hence this apparent association is generated by all the traits H, T and F being phylogenetically constrained. In line with our assumptions, the figure suggests that variation in trait 4 (B) is independent of the phylogeny and of the other traits.

## Simulating environmental and species data
As the next step, we simulate the environmental and species data. With respect to the environmental conditions, we assume that there is variation in habitat type and in climatic conditions. Concerning habitat, we assume that the sampling units are located either in open habitats or in forested habitats. Concerning climate, we assume that the sampling units differ in their thermal conditions, which we characterize by a continuous covariate.

```{r}
set.seed(1)
n = 200
habitat = factor(sample(x=c("forest","open"),size=n,replace=TRUE))
climate = rnorm(n)
```

The next step is to define the species niches, i.e. how the species abundances depend on the match between their traits and the environmental conditions. In the script below, we assume that the fecundity of the species has an additive effect on the linear predictor, so that species with higher fecundity will be more abundant. We assume that the trait habitat use measures the preference of the species to forests, so that for forest habitats we add this trait value to the linear predictor whereas for open habitats we subtract it from the linear predictor. We have further subtract the squared difference between the climatic conditions at the sampling unit and the thermal optimum of the species, making the linear predictor and hence species abundance smaller if these two do not match. 

```{r}
L = matrix(0,nrow=n,ncol=ns)
for (i in 1:n){
   L[i,] = L[i,] + traits$fecundity
   L[i,] = L[i,] + (if(habitat[i]=="forest"){1}else{-1})*traits$habitat.use
   L[i,] = L[i,] - (climate[i]-traits$thermal.optimum)^2/4
}
```

Finally, we assume that body size influences the competition among the species, so that large bodied species compete for certain types of resources, whereas small bodied species compete for other types of resources, and species with intermediate body size compete for a third kind of resources. We implement this by assuming that a subset of species pairs belonging to the same body size class show a negative correlation with each other.

```{r}
set.seed(1)
rho = -0.5
W = diag(ns)
for(repl in 1:1000){
   spp = sample(1:ns,2)
   W1 = W
   W1[spp[1],spp[2]] = rho
   W1[spp[2],spp[1]] = rho
   if(min(eigen(W1)$values)>0){W=W1}
}
min(eigen(W)$values)
print(paste0("number of competing species pairs: ",sum(W==rho)/2))
```

The reason why we did not assume that all species pairs belonging to the same body size class would show a strong negative correlation with each other is that this would be logically impossible. Thinking in terms of species occurrence, assume that we would like to implement a strong avoidance among species A, B and C. We could start by assuming that the species A and B show competitive exclusion and that they do not occupy the same sampling units, so that a sampling unit is occupied either by species A or by species B. We could likewise assume that also the species B and C show competitive exclusion and thus a given sampling unit is occupied either by species B or by species C. But these two assumptions lead to the situation where the species A and C will necessarily be found from the same sampling units, because they both would be found from those sampling units where B is not present. Thus, it would not possible to assume further that due to competitive exclusion between species A and C, these two would also occupy different sampling units. While we could modify this example in many ways to avoid the problem (e.g., one sampling unit can be occupied only by one of the species A, B and C), it makes the point that pair-wise associations among species need to be compatible with each other.

In the above script, we ensure that the smallest eigenvalue of the correlation matrix `W` is positive, i.e. we ensure that matrix `W` remains positive definite. The condition of positive definiteness corresponds to the intuitive assumption that the associations must be logically feasible, in the sense discussed above. In the above script, the more negative the correlation `rho` between a competing species pair is assumed to be, the smaller will be the number of species pairs that can show that negative correlation with each other. We note that the situation is not the identical with respect to positive associations. For example, it can be that some sampling units are occupied by all species whereas in other sampling units none of the species is present, creating a strong positive association among all species pairs.

We next simulate the effects of competitive interactions by adding to the linear predictor random deviates from the multivariate normal distribution where the variance-covariance matrix is set to the above constructed correlation matrix.

```{r}
a = mvrnorm(n=n, mu=rep(0,ns), Sigma=W)
L = L + a
```


To generate the species data, we finally need to decide about the link function and error distribution. For simplicity, we assume here that the data are normally distributed. We thus simply add some independent residual variation, where we assume the variance parameter to be identical for each species. We note that as the elements of the matrix `Y` can include any real numbers, they might measure species abundance e.g. in the units of log-transformed biomass.

To make the species data interpretable with respect to the phylogenetic and trait information, we associate the data matrix `Y` with the species names.
```{r}
Y = L + mvrnorm(n=n, mu=rep(0,ns), Sigma=diag(ns))
colnames(Y) = spnames
```

#HMSC analyses of the data with the "correct" model

We are next ready to analyse the data with HMSC. In this section, we consider the "correct" model for which the assumptions are exactly in line with how we generated the data. Let us know in passing that with real data, the model will always be to some extent misspecified as the underlying mechanisms are not known. In the next sections, we will examine the influence of model misspecification by examining how the results of the analyses change if we e.g. fail to account for some of the traits or environmental covariates.

To define a HMSC model that best corresponds to how the data were simulated, we include as fixed effects the categorical variable of habitat type and the continuous covariate of climate. To allow for the possibility of an intermediate thermal optimum, we also include the squared effect of climate. As species traits, we include habitat use (H), thermal optimum (T) and fecundity (F). We do not include body size into the traits because in the HMSC model the traits are used to model the responses of the species to the environmental covariates, not the species-to-species residual associations. Instead, we attempt to capture the influence of competitive interactions by adding a random effect at the sampling unit level. Further, we include the phylogenetic relationships among the species to estimate the strength of the phylogenetic signal in the data. We thus construct the HMSC model as

```{r}
XData = data.frame(climate=climate, habitat=habitat)
studyDesign = data.frame(sample = sprintf('sample_%.3d',1:n))
rL = HmscRandomLevel(units = studyDesign$sample)
XFormula = ~habitat + poly(climate,degree = 2,raw = TRUE)
TrFormula = ~habitat.use + thermal.optimum + fecundity
m = Hmsc(Y=Y, XData=XData, XFormula = XFormula,
         TrData = traits, TrFormula = TrFormula,
         phyloTree = phy,
         studyDesign=studyDesign, ranLevels=list(sample=rL))
```

We then choose the MCMC sampling parameters and fit the model. If the aim of the reader is to run through the markdown behind the vignette fast to see how the model objects are constructed and how the functions are called, we recommend running minimal amount of MCMC sampling, which can be obtained by setting `test.run = TRUE`. If the aim is to replicate the results that are given in the pdf version of the vignette, the user should increase the amount of MCMC sampling, e.g. by setting `test.run = FALSE`.

```{r}
nChains = 2
test.run = TRUE
if (test.run){
   #with this option, the vignette evaluates in ca. 10 minutes in a laptop
   thin = 1
   samples = 1000
   transient = 500
} else {
   #with this option, the vignette evaluates in ca. 2 hrs in a laptop
   thin = 10
   samples = 1000
   transient = 500
}
verbose = 0
m = sampleMcmc(m, thin = thin, samples = samples, transient = transient,
                    nChains = nChains, verbose = verbose)
```
##MCMC convergence

We evaluate MCMC convergence in terms of four kinds of parameters about which we are especially interested about: the species niches `Beta`, the influence of traits on species niches `Gamma`, residual species associations `Omega`, and the strength of phylogenetic signal `rho`. As there are `r ns` species, the matrix `Omega` is a `r ns` x `r ns` matrix with `r ns*ns` elements. To avoid excessive computational times, we evaluate MCMC convergence for `Omega` only for a subsample of 100 randomly selected species pairs.
```{r}
mpost = convertToCodaObject(m)
par(mfrow=c(3,2))
ess.beta = effectiveSize(mpost$Beta)
psrf.beta = gelman.diag(mpost$Beta,multivariate=FALSE)$psrf
hist(ess.beta)
hist(psrf.beta)
ess.gamma = effectiveSize(mpost$Gamma)
psrf.gamma = gelman.diag(mpost$Gamma,multivariate=FALSE)$psrf
hist(ess.gamma)
hist(psrf.gamma)
sppairs = matrix(sample(x = 1:ns^2, size = 100))
tmp = mpost$Omega[[1]]
for (chain in 1:length(tmp)){
   tmp[[chain]] = tmp[[chain]][,sppairs]
}
ess.omega = effectiveSize(tmp)
psrf.omega = gelman.diag(tmp,multivariate=FALSE)$psrf
hist(ess.omega)
hist(psrf.omega)
print("ess.rho:")
effectiveSize(mpost$Rho)
print("psrf.rho:")
gelman.diag(mpost$Rho)$psrf
```

The convergence diagnostics suggest reasonably good MCMC convergence, as most potential scale reduction factors are close to one and effective sample sizes relatively high. We note that this is largely thanks to the assumption of a normal model, so that for e.g. probit model for presence-absence data we should most likely run much longer MCMC chains.

## Model fit and variance partitioning

As usual, we measure the explanatory power of the model by $R^2$.

```{r}
preds = computePredictedValues(m)
MF = evaluateModelFit(hM=m, predY=preds)
hist(MF$R2,xlim = c(0,1),main=paste0("mean = ",mean(MF$R2)))
```

We observe that the explanatory power is relatively high for all species, which is not surprising, as we assumed that the species respond strongly to the environmental variation in habitat and climatic conditions.

The explained variation can be partitioned into components related to the fixed and the random effects. Before doing so, let us have a look at the design matrix `X` of the model.

```{r}
head(m$X)
```

The design matrix `X` has been derived from `XData` and `XFormula` when constructing the HMSC object. Following the usual conventions of building generalized linear models, the design matrix includes the intercept by default. The categorical explanatory variables are expanded into dummy variables indicating which level is present in the focal sampling unit. Here the second column corresponds to the explanatory variable habitat, and a value 1 means that the habitat is open habitat. To avoid confounding with the intercept, one of the levels is left as the reference level, for which reason there is no column indicating when the habitat is forest habitat (this is the case when habitat is not in habitat). The continuous covariate climate is present here in two columns, which model its linear and quadratic effects.

When making a variance partitioning, the user can group the fixed effects (i.e., the columns of the design matrix) in any way that works best for presenting the results. It is generally recommended to group variables related to the same theme, as then the variance component accounts also for co-variation within the group, whereas co-variation among groups is ignored in the way variance partitioning is computed in HMSC. Here we wish to show separately the influences of habitat and climate. We call habitat as group 1, and climate as group 2. The column 2 of the design matrix belongs to group 1, so we define `group[2]=1`.
The columns 3 and 4 of the design matrix belongs to group 2, so we define `group[3]=2` and `group[4]=2`. The intercept does not have any variation, and thus it will not contribute to the variance partitioning. Thus we may place it e.g. to group 1 as `group[1]=1`.

```{r}
VP = computeVariancePartitioning(m, group = c(1,1,2,2),groupnames=c("habitat","climate"))
plotVariancePartitioning(m, VP = VP)
```
We observe that both components of environmental variation (climate and habitat) explain substantial proportions of the explained variance. In contrast, the random effects explain only a minor part of the variation. The traits explain almost all ($R^2$ = `r round(100*VP$traitR2)`%) of the variation in the species niches. This is because we have included in the HMSC model those traits that truly matter in how species respond to the environmental variation.

## Parameter estimates
As we have `r ns` species and four species-specific parameters (one for each column of the design matrix), there are `r 4*ns` $\beta$ parameters in total. Thus it is more convenient to look at these as a graph rather than a vast table of numbers. In the function `plotBeta`, we use the option `plotTree = TRUE` to plot the phylogenetic tree next to the parameter estimates.

```{r}
postBeta = getPostEstimate(m, parName="Beta")
plotBeta(m, post=postBeta, param="Support",
         plotTree = TRUE, supportLevel = 0.95,spNamesNumbers = c(F,F))
```

This graph contains a lot of information. First of all, there is strong posterior support for many parameters being positive (red) or negative (blue), i.e. there are strong signals of environmental filtering. Some species show preference to open habitats (red colour in the second column C2), other show avoidance to open habitats and thus preference for forests (blue colour in the column C2). Species with preference to open and forest habitats are not randomly ordered across the phylogeny, but sister species show similar responses, corresponding to our assumption that we assumed the species trait controlling for habitat preference be phylogenetically constrained. Essentially all species show a negative response to the second order term of climate (column C4), meaning that their estimated climatic niches show an intermediate optimum. A phylogenetic signal is clear also in column C3 which shows the linear effect of the climatic niche and thus determines at which temperature the species niche peaks.

While the `Beta` parameters model species niches, the `Gamma` parameters model how species traits influence their niches. Let us next visualize these parameters.

```{r}
postGamma = getPostEstimate(m, parName="Gamma")
plotGamma(m, post=postGamma, param="Support", supportLevel = 0.95)
```
In this graph, the rows correpond to the species traits (more precisely, the columns of the design matrix `Tr` that is derived from `TrData` and `TrFormula`), and the rows to the environmental covariates  (more precisely, the columns of the design matrix `X` illustrated above). This plot yields a compact summary of the results at the community level. First, we observe a negative association between T2 (the trait `habitat.use`) and C2 (the level `open` of the environmental covariate `habitat`), meaning that those species which have a high value of the trait habitat use tend to be less common in open habitats than in the reference habitat of forest. This makes perfect sense, as we assumed that habitat use influences the preference for forests. Second, we observe a positive association between T4 (the trait `thermal.optimum`) and the covariate C3 (the linear effect of the environmental covariate `climate`). This also makes perfect sense, as it means that species with a higher thermal optimum are found more abundant from sampling units with warm climate. Third, we observe a negative association between T1 (the trait `intercept`) and the covariate C4 (`second order response to climate`). This correspond to the result that we observed already in the `Beta` plot that all species generally show a negative response to the second order term of climate, and thus their response curve peaks at some intermediate temperature. Fourth, we observe a positive association between the trait T4 (`fecundity`) and the environmental covariate C1 `intercept`. This means that there is a positive relationship between species general abundance and fecundity.

Let us next visualize the estimated residual associations among the species. We set `supportLevel = 0.8` to use a relatively mild threshold level of statistical support in order to avoid missing some of the associations that may show only a weak signal.

```{r}
OmegaCor = computeAssociations(m)
supportLevel = 0.8
toPlot = ((OmegaCor[[1]]$support>supportLevel) 
          + (OmegaCor[[1]]$support<(1-supportLevel))>0)*OmegaCor[[1]]$mean
corrplot(toPlot, method = "color", 
         col=colorRampPalette(c("blue","white","red"))(200),
         title=paste("random effect level:",m$rLNames[1]), mar=c(0,0,1,0))
```
We may compare these estimated associations to those that we assumed in generating data. Thus we use next `corrplot` to plot the matrix `W` showing which species pairs were assumed to compete with each other.

```{r}
rownames(W) = spnames
colnames(W) = spnames
corrplot(W, method = "color", 
         col=colorRampPalette(c("blue","white","red"))(200),
         title=paste("random effect level:",m$rLNames[1]), mar=c(0,0,1,0))
```

We observe that the assumed (`W`) and estimated (`Omega`) matrices are consistent in the sense that both contain a small number of negative associations, the majority of the species pairs having no association. To check how often the estimated negative associations match with the same species pairs for 
which they were recorded to, we can compute the proportions of "true positives", "false positives", "true negatives" and "false negatives".

```{r}
neg = OmegaCor[[1]]$support<(1-supportLevel)
nonneg = !neg
diag(nonneg)=FALSE
ma = rbind(c(mean(W[neg]<0),mean(W[neg]==0)),c(mean(W[nonneg]<0),mean(W[nonneg]==0)))
colnames(ma) = c("W<0","W==0")
rownames(ma) = c("Omega<0", "Omega>=0")
ma
```

Out of those cases where we estimated a negative association, the underlying true association was negative in `r round(100*ma[1,1])`% of the cases and thus zero in the remaining `r round(100*ma[1,2])`% of the cases. Out of those cases where we did not estimate a negative association, the underlying true association was negative in `r round(100*ma[2,1])`% of the cases and thus zero in the remaining `r round(100*ma[2,2])`% of the cases. The numbers match better than expected by random, but still they show that accurate estimation of a few negatively interacting species pairs is difficult. Actually the latent factor structure of HMSC is perhaps not best suited for this purpose, as in this case the assumption of a sparse interaction matrix would be a better match with the data.

We finally look at the strength of the phylogenetic signal that was estimated from the data.

```{r}
summary(mpost$Rho)
```

We note that the phylogenetic signal parameter $\rho$ of HMSC does not ask whether the species traits are correlated with the phylogeny, which question is often in the focus of phylogenetic analyses. Instead, the phylogenetic signal parameter $\rho$ measures whether the species niches (i.e., their responses to the environmental covariates, as measured by the $\beta$ parameters) show phylogenetic correlations. Furthermore, this is evaluated after accounting for the influence of species traits on species niches (as modelled by the $\gamma$ parameters). In the ideal case, we would not see any phylogenetic signal in the present case, because we have propagated the influence of phylogeny solely through those species traits that we included in the HMSC model. Thus, the estimated phylogenetic signal is simply due to the difficulty in separating statistically the influences of phylogenetically structured traits from a potential direct influence of the phylogeny itself.

## Plotting variation over environmental gradients

Sometimes the values of the primary parameters `Beta` and `Gamma` can be difficult to interpret, especially if there are categorical traits or environmental covariates in which case their effects are coded through dummy variables. One alternative for visualizing the results is to plot how the community changes over some environmental gradient of interest. This can be one in HMSC by constructing environmental gradients with the function `constructGradient`, then predicting communities over those gradients by the function `predict`, and finally using `plotGradient`to visualize the predicted variation. We consider first a climatic gradient.


```{r}
Gradient = constructGradient(m,focalVariable = "climate",
                             non.focalVariables = list("habitat"=list(3,"open")))
Gradient$XDataNew
```

As `climate` is a continuous covariate, the constructed gradient involves a grid of its values ranging from the smallest to the largest observed in the data. As we will make predictions of species communities, we need to assume values for all explanatory variables, not only to the focal one. We have set here the value of the non-focal variable habitat to open habitat, and we thus imagine that we sample different parts of the climatic gradient solely in open habitats. We then generate predictions for this community, and plot them over the environmental gradient.  

```{r}
predY = predict(m, XData=Gradient$XDataNew, studyDesign=Gradient$studyDesignNew, 
                ranLevels=Gradient$rLNew, expected=TRUE)
plotGradient(m, Gradient, pred=predY, measure="S", showData = TRUE)
```

We set `measure="S"` to plot the summed abundance over all species, i.e. the row sum of the predicted communities. The predicted response peaks at intermediate climate, which response is also visible in the raw data. This is because, by our assumptions, some species are specialized to cool climate, some to warm climate, and others to intermediate climate, leading to the pattern where intermediate climate is on average the most suitable one. We note that with presence-absence data modelled with the probit model, the measure `S` would give the expected species richness.

We can visualize the same predictions for individual species by setting `measure="Y"` and by using `index` the species to be visualized (as ordered in the matrix `m$Y`).

```{r}
plotGradient(m, Gradient, pred=predY, measure="Y", index = 1, showData = TRUE)
```
This figure shows that `species_089` is most abundant at relatively cool climates. Finally, by selecting `measure="T"` we can visualize how community weighted mean traits behave over the environmental gradient. Now `index` selects the trait (as ordered in the matrix `m$Tr`).

```{r}
plotGradient(m, Gradient, pred=predY, measure="T", index = 3, showData = TRUE)
```
This figure shows that, as expected, the community-weighted mean of thermal optimum is higher in warmer climates. For normally distributed data, HMSC computes community-weighted mean traits by using exponentially transformed predictions as weights, to avoid weighting with negative numbers.

Let us then construct an environmental gradient over the habitat types.

```{r}
Gradient = constructGradient(m,focalVariable = "habitat",
                             non.focalVariables = list("climate"=list(1)))
Gradient$XDataNew
```

As habitat is a categorical variable, we the gradient involves only two sampling units, one belonging to forest and the other one to open habitat. We have decided to normalize the climatic variable to its overall mean in the data (for other options, see the F1-help for `constructGradient`).

Let us select the species for which the trait value for habitat use is the highest, and then plot how that species responds to the habitat gradient.

```{r}
predY = predict(m, XData=Gradient$XDataNew, studyDesign=Gradient$studyDesignNew,
                ranLevels=Gradient$rLNew, expected=TRUE)
plotGradient(m, Gradient, pred=predY, measure="Y", index=which.max(m$TrData$habitat.use),
             showData = TRUE, jigger = 0.2)
```
As expected, the species shows a higher predicted response to forests than to open habitats, which pattern is visible also in the raw data. We note that as habitat is a categorical covariate, now the environmental gradient is more naturally presented in terms of a boxplot. We further note that we have set `jigger = 0.2` to randomly move the observed data (the dots) in the horizontal direction and thus to avoid overlapping points.

We finally set `measure="T"` to examine how the community weighted mean trait of habitat use varies between the two habitat types.

```{r}
predY = predict(m, XData=Gradient$XDataNew, studyDesign=Gradient$studyDesignNew,
                ranLevels=Gradient$rLNew, expected=TRUE)
plotGradient(m, Gradient, pred=predY, measure="T", index=2, showData = TRUE, jigger = 0.2)
```

As expected, the average value of this trait (weighted by exponentially transformed species abundances) is higher in forests than in open habitats.

#HMSC analyses of misspecified models

With real data, there is no "correct" model structure that would exactly correspond to the community assembly processes that generated the data. Thus, like any model, also the HMSC model will always be "wrong". We next briefly examine what happens if we misspecify the model by leaving out some environmental covariates or traits. 

## Missing environmental covariate

We first repeat some of the above analyses with a missing environmental covariate. We assume that the researcher would not have realized that the data are sampled from two different habitats, or that the researcher did not consider it to matter for the species abundances. Thus, we fit otherwise the same model, but include only climate as fixed effects.

```{r}
XFormula.1 = ~poly(climate,degree = 2,raw = TRUE)
m = Hmsc(Y=Y, XData=XData, XFormula = XFormula.1,
         TrData = traits, TrFormula = TrFormula,
         phyloTree = phy,
         studyDesign=studyDesign, ranLevels=list(sample=rL))

m = sampleMcmc(m, thin = thin, samples = samples, transient = transient,
                    nChains = nChains, verbose = verbose)
preds = computePredictedValues(m)
MF = evaluateModelFit(hM=m, predY=preds)
hist(MF$R2,xlim = c(0,1),main=paste0("mean = ",mean(MF$R2)))
VP = computeVariancePartitioning(m, group = c(1,1,1),groupnames=c("climate"))
plotVariancePartitioning(m, VP = VP)
```
Expectedly, the explanatory power is now lower, and a larger proportion of explained variation is attributed to the random effects. Let us plot the structure of the species associations, as estimated by the random effect.

```{r}
OmegaCor = computeAssociations(m)
supportLevel = 0.95
toPlot = ((OmegaCor[[1]]$support>supportLevel) 
          + (OmegaCor[[1]]$support<(1-supportLevel))>0)*OmegaCor[[1]]$mean
corrplot(toPlot, method = "color", 
         col=colorRampPalette(c("blue","white","red"))(200),
         title=paste("random effect level:",m$rLNames[1]), mar=c(0,0,1,0))
```

We observe now a much richer structure of associations. This is because the responses of the species to to habitat are not modelled through the fixed effects, and thus the random effect is capturing part of that variation. Species pairs that prefer the same habitat type are now estimated to have a positive association, whereas species pairs that prefer different habitat types are now estimated to have a negative association.

## Missing traits

Let us next assume that we would have trait data only on habitat use, but we would lack information on species fecundities and thermal optima. We repeat the above analyses with a model modified to correspond this assumption. 

```{r}
TrFormula.1 = ~habitat.use
m = Hmsc(Y=Y, XData=XData, XFormula = XFormula,
         TrData = traits, TrFormula = TrFormula.1,
         phyloTree = phy,
         studyDesign=studyDesign, ranLevels=list(sample=rL))

m = sampleMcmc(m, thin = thin, samples = samples, transient = transient,
                    nChains = nChains, verbose = verbose)
preds = computePredictedValues(m)
MF = evaluateModelFit(hM=m, predY=preds)
hist(MF$R2,xlim = c(0,1),main=paste0("mean = ",mean(MF$R2)))
VP = computeVariancePartitioning(m, group = c(1,1,2,2),groupnames=c("habitat","climate"))
plotVariancePartitioning(m, VP = VP)
```
This model is very similar to the full model in terms of the explanatory power, as well as in terms of the variance partitioning. However, now the traits explain the much smaller part ($R^2$ = `r round(100*VP$traitR2)`%) of the variation in the species niches as was the case with the full model. This is because we are missing some relevant traits that would have explained the remaining part of the variation in species niches.

Let us then examine the posterior distribution for the phylogenetic signal parameter.

```{r}
summary(mpost$Rho)
```

This parameter is now estimated to be higher than in the full model. This is the case because now residual variation in species niches (not explained by the traits) include a phylogenetic signal, which signal is generated by the phylogenetic structure of the missing traits.

